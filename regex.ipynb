{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['begin', 'began', 'begun', 'begins', 'begin']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "with open('regex-target-text-sample.txt', 'r') as f:\n",
    "    str = f.read()\n",
    "pttn = r'beg[iau]ns?'\n",
    "re.findall(pttn, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['row', 'fox', 'dog']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "str = 'The quick brown fox jumps over the lazy dog'\n",
    "pttn = re.compile(r'\\wo\\w')\n",
    "re.findall(pttn, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0123456789'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import string\n",
    "string.ascii_letters\n",
    "string.digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['begin', 'began', 'begun', 'begin']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "str = 'begin began begun bigins begining'\n",
    "pttn = r'beg[iau]n'\n",
    "re.findall(pttn, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['542-', '270-']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "str = '<dl>(843) 542-4256</dl> <dl>(431) 270-9664</dl>'\n",
    "pttn = r'\\d\\d\\d\\-'\n",
    "re.findall(pttn, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['er', 'er', 'er']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['er', 'er']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "str = 'never ever verb however everest'\n",
    "pttn = r'er\\b'\n",
    "re.findall(pttn, str)\n",
    "pttn = r'er\\B'\n",
    "re.findall(pttn, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google', 'gooogle', 'goooogle', 'goooooogle']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['google', 'gooogle', 'goooogle']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['coloured', 'colored']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['520', '52000', '5200000', '520000000', '520000000000']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import re\n",
    "with open('regex-target-text-sample.txt', 'r') as f:\n",
    "    str = f.read()\n",
    "\n",
    "pttn = r'go+gle'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "pttn = r'go{2,5}gle'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "pttn = r'colou?red'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "pttn = r'520*'\n",
    "re.findall(pttn, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['er', 'er', 'er', 'er']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['e', 'r', 'r', 'r', 'e', 'r', 'e', 'r', 'e', 'e', 'r', 'e', 'e']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['er', 'er', 'er', 'er']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import re\n",
    "\n",
    "str = 'error wonderer severeness'\n",
    "\n",
    "pttn = r'er'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "pttn = r'[er]'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "pttn = r'(er)'\n",
    "re.findall(pttn, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['err', 'er', 'er', 'er']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['err', 'r', 'erer', 'e', 'ere', 'e']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['er', 'er', 'er']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import re\n",
    "\n",
    "str = 'error wonderer severeness'\n",
    "\n",
    "pttn = r'er+'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "pttn = r'[er]+'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "pttn = r'(er)+'\n",
    "re.findall(pttn, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['begin', 'began', 'begun', 'begin', 'begin']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "str = 'begin began begun begins beginn'\n",
    "pttn = r'begin|began|begun'\n",
    "re.findall(pttn, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'e', 'a', 'a', 'e', 'a', 'a', '|', 'e']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'e', 'a', 'a', 'e', 'a', 'a', '|', 'e']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'e', 'a', 'a', 'e', 'a', 'a', 'e']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'e', 'a', 'a', 'e', 'a', 'a', 'e']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'e', 'a', 'a', 'e', 'a', 'a', '|', 'e']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import re\n",
    "\n",
    "str = 'achroiocythaemia achroiocythemia a|e'\n",
    "pttn = r'[a|ae]'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "pttn = r'[a|e]'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "pttn = r'[ae]'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "pttn = r'[(ae)]'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "pttn = r'[a|ae|(ae)]'\n",
    "re.findall(pttn, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('white', 'black')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'The black dog wears a white hat.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'The white dog wears a white hat.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "str = 'The white dog wears a black hat.'\n",
    "pttn = r'The (white|black) dog wears a (white|black) hat.'\n",
    "re.findall(pttn, str)\n",
    "\n",
    "repl = r'The \\2 dog wears a \\1 hat.'\n",
    "re.sub(pttn, repl, str)\n",
    "\n",
    "repl = r'The \\1 dog wears a \\1 hat.'\n",
    "re.sub(pttn, repl, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'The black dog wears a black hat.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "str = 'The white dog wears a black hat.'\n",
    "pttn = r'The (?:white|black) dog wears a (white|black) hat.'\n",
    "re.findall(pttn, str)                   # 只捕获了一处，也就是说只有一个值将来可以被引用\n",
    "\n",
    "repl = r'The \\1 dog wears a \\1 hat.'    # 之前的一处捕获，在替换时可被多次引用\n",
    "re.sub(pttn, repl, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/jezhiggins/eliza.py/master/eliza.py\n",
    "#----------------------------------------------------------------------\n",
    "#  eliza.py\n",
    "#\n",
    "#  a cheezy little Eliza knock-off by Joe Strout\n",
    "#  with some updates by Jeff Epler\n",
    "#  hacked into a module and updated by Jez Higgins\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "class eliza:\n",
    "  def __init__(self):\n",
    "    self.keys = list(map(lambda x:re.compile(x[0], re.IGNORECASE),gPats))\n",
    "    self.values = list(map(lambda x:x[1],gPats))\n",
    "\n",
    "  #----------------------------------------------------------------------\n",
    "  # translate: take a string, replace any words found in dict.keys()\n",
    "  #  with the corresponding dict.values()\n",
    "  #----------------------------------------------------------------------\n",
    "  def translate(self,str,dict):\n",
    "    words = str.lower().split()\n",
    "    keys = dict.keys();\n",
    "    for i in range(0,len(words)):\n",
    "      if words[i] in keys:\n",
    "        words[i] = dict[words[i]]\n",
    "    return ' '.join(words)\n",
    "\n",
    "  #----------------------------------------------------------------------\n",
    "  #  respond: take a string, a set of regexps, and a corresponding\n",
    "  #    set of response lists; find a match, and return a randomly\n",
    "  #    chosen response from the corresponding list.\n",
    "  #----------------------------------------------------------------------\n",
    "  def respond(self,str):\n",
    "    # find a match among keys\n",
    "    for i in range(0, len(self.keys)):\n",
    "      match = self.keys[i].match(str)\n",
    "      if match:\n",
    "        # found a match ... stuff with corresponding value\n",
    "        # chosen randomly from among the available options\n",
    "        resp = random.choice(self.values[i])\n",
    "        # we've got a response... stuff in reflected text where indicated\n",
    "        pos = resp.find('%')\n",
    "        while pos > -1:\n",
    "          num = int(resp[pos+1:pos+2])\n",
    "          resp = resp[:pos] + \\\n",
    "            self.translate(match.group(num),gReflections) + \\\n",
    "            resp[pos+2:]\n",
    "          pos = resp.find('%')\n",
    "        # fix munged punctuation at the end\n",
    "        if resp[-2:] == '?.': resp = resp[:-2] + '.'\n",
    "        if resp[-2:] == '??': resp = resp[:-2] + '?'\n",
    "        return resp\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# gReflections, a translation table used to convert things you say\n",
    "#    into things the computer says back, e.g. \"I am\" --> \"you are\"\n",
    "#----------------------------------------------------------------------\n",
    "gReflections = {\n",
    "  \"am\"   : \"are\",\n",
    "  \"was\"  : \"were\",\n",
    "  \"i\"    : \"you\",\n",
    "  \"i'd\"  : \"you would\",\n",
    "  \"i've\"  : \"you have\",\n",
    "  \"i'll\"  : \"you will\",\n",
    "  \"my\"  : \"your\",\n",
    "  \"are\"  : \"am\",\n",
    "  \"you've\": \"I have\",\n",
    "  \"you'll\": \"I will\",\n",
    "  \"your\"  : \"my\",\n",
    "  \"yours\"  : \"mine\",\n",
    "  \"you\"  : \"me\",\n",
    "  \"me\"  : \"you\"\n",
    "}\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# gPats, the main response table.  Each element of the list is a\n",
    "#  two-element list; the first is a regexp, and the second is a\n",
    "#  list of possible responses, with group-macros labelled as\n",
    "#  %1, %2, etc.\n",
    "#----------------------------------------------------------------------\n",
    "gPats = [\n",
    "  [r'I need (.*)',\n",
    "  [  \"Why do you need %1?\",\n",
    "    \"Would it really help you to get %1?\",\n",
    "    \"Are you sure you need %1?\"]],\n",
    "\n",
    "  [r'Why don\\'?t you ([^\\?]*)\\??',\n",
    "  [  \"Do you really think I don't %1?\",\n",
    "    \"Perhaps eventually I will %1.\",\n",
    "    \"Do you really want me to %1?\"]],\n",
    "\n",
    "  [r'Why can\\'?t I ([^\\?]*)\\??',\n",
    "  [  \"Do you think you should be able to %1?\",\n",
    "    \"If you could %1, what would you do?\",\n",
    "    \"I don't know -- why can't you %1?\",\n",
    "    \"Have you really tried?\"]],\n",
    "\n",
    "  [r'I can\\'?t (.*)',\n",
    "  [  \"How do you know you can't %1?\",\n",
    "    \"Perhaps you could %1 if you tried.\",\n",
    "    \"What would it take for you to %1?\"]],\n",
    "\n",
    "  [r'I am (.*)',\n",
    "  [  \"Did you come to me because you are %1?\",\n",
    "    \"How long have you been %1?\",\n",
    "    \"How do you feel about being %1?\"]],\n",
    "\n",
    "  [r'I\\'?m (.*)',\n",
    "  [  \"How does being %1 make you feel?\",\n",
    "    \"Do you enjoy being %1?\",\n",
    "    \"Why do you tell me you're %1?\",\n",
    "    \"Why do you think you're %1?\"]],\n",
    "\n",
    "  [r'Are you ([^\\?]*)\\??',\n",
    "  [  \"Why does it matter whether I am %1?\",\n",
    "    \"Would you prefer it if I were not %1?\",\n",
    "    \"Perhaps you believe I am %1.\",\n",
    "    \"I may be %1 -- what do you think?\"]],\n",
    "\n",
    "  [r'What (.*)',\n",
    "  [  \"Why do you ask?\",\n",
    "    \"How would an answer to that help you?\",\n",
    "    \"What do you think?\"]],\n",
    "\n",
    "  [r'How (.*)',\n",
    "  [  \"How do you suppose?\",\n",
    "    \"Perhaps you can answer your own question.\",\n",
    "    \"What is it you're really asking?\"]],\n",
    "\n",
    "  [r'Because (.*)',\n",
    "  [  \"Is that the real reason?\",\n",
    "    \"What other reasons come to mind?\",\n",
    "    \"Does that reason apply to anything else?\",\n",
    "    \"If %1, what else must be true?\"]],\n",
    "\n",
    "  [r'(.*) sorry (.*)',\n",
    "  [  \"There are many times when no apology is needed.\",\n",
    "    \"What feelings do you have when you apologize?\"]],\n",
    "\n",
    "  [r'Hello(.*)',\n",
    "  [  \"Hello... I'm glad you could drop by today.\",\n",
    "    \"Hi there... how are you today?\",\n",
    "    \"Hello, how are you feeling today?\"]],\n",
    "\n",
    "  [r'I think (.*)',\n",
    "  [  \"Do you doubt %1?\",\n",
    "    \"Do you really think so?\",\n",
    "    \"But you're not sure %1?\"]],\n",
    "\n",
    "  [r'(.*) friend (.*)',\n",
    "  [  \"Tell me more about your friends.\",\n",
    "    \"When you think of a friend, what comes to mind?\",\n",
    "    \"Why don't you tell me about a childhood friend?\"]],\n",
    "\n",
    "  [r'Yes',\n",
    "  [  \"You seem quite sure.\",\n",
    "    \"OK, but can you elaborate a bit?\"]],\n",
    "\n",
    "  [r'(.*) computer(.*)',\n",
    "  [  \"Are you really talking about me?\",\n",
    "    \"Does it seem strange to talk to a computer?\",\n",
    "    \"How do computers make you feel?\",\n",
    "    \"Do you feel threatened by computers?\"]],\n",
    "\n",
    "  [r'Is it (.*)',\n",
    "  [  \"Do you think it is %1?\",\n",
    "    \"Perhaps it's %1 -- what do you think?\",\n",
    "    \"If it were %1, what would you do?\",\n",
    "    \"It could well be that %1.\"]],\n",
    "\n",
    "  [r'It is (.*)',\n",
    "  [  \"You seem very certain.\",\n",
    "    \"If I told you that it probably isn't %1, what would you feel?\"]],\n",
    "\n",
    "  [r'Can you ([^\\?]*)\\??',\n",
    "  [  \"What makes you think I can't %1?\",\n",
    "    \"If I could %1, then what?\",\n",
    "    \"Why do you ask if I can %1?\"]],\n",
    "\n",
    "  [r'Can I ([^\\?]*)\\??',\n",
    "  [  \"Perhaps you don't want to %1.\",\n",
    "    \"Do you want to be able to %1?\",\n",
    "    \"If you could %1, would you?\"]],\n",
    "\n",
    "  [r'You are (.*)',\n",
    "  [  \"Why do you think I am %1?\",\n",
    "    \"Does it please you to think that I'm %1?\",\n",
    "    \"Perhaps you would like me to be %1.\",\n",
    "    \"Perhaps you're really talking about yourself?\"]],\n",
    "\n",
    "  [r'You\\'?re (.*)',\n",
    "  [  \"Why do you say I am %1?\",\n",
    "    \"Why do you think I am %1?\",\n",
    "    \"Are we talking about you, or me?\"]],\n",
    "\n",
    "  [r'I don\\'?t (.*)',\n",
    "  [  \"Don't you really %1?\",\n",
    "    \"Why don't you %1?\",\n",
    "    \"Do you want to %1?\"]],\n",
    "\n",
    "  [r'I feel (.*)',\n",
    "  [  \"Good, tell me more about these feelings.\",\n",
    "    \"Do you often feel %1?\",\n",
    "    \"When do you usually feel %1?\",\n",
    "    \"When you feel %1, what do you do?\"]],\n",
    "\n",
    "  [r'I have (.*)',\n",
    "  [  \"Why do you tell me that you've %1?\",\n",
    "    \"Have you really %1?\",\n",
    "    \"Now that you have %1, what will you do next?\"]],\n",
    "\n",
    "  [r'I would (.*)',\n",
    "  [  \"Could you explain why you would %1?\",\n",
    "    \"Why would you %1?\",\n",
    "    \"Who else knows that you would %1?\"]],\n",
    "\n",
    "  [r'Is there (.*)',\n",
    "  [  \"Do you think there is %1?\",\n",
    "    \"It's likely that there is %1.\",\n",
    "    \"Would you like there to be %1?\"]],\n",
    "\n",
    "  [r'My (.*)',\n",
    "  [  \"I see, your %1.\",\n",
    "    \"Why do you say that your %1?\",\n",
    "    \"When your %1, how do you feel?\"]],\n",
    "\n",
    "  [r'You (.*)',\n",
    "  [  \"We should be discussing you, not me.\",\n",
    "    \"Why do you say that about me?\",\n",
    "    \"Why do you care whether I %1?\"]],\n",
    "\n",
    "  [r'Why (.*)',\n",
    "  [  \"Why don't you tell me the reason why %1?\",\n",
    "    \"Why do you think %1?\" ]],\n",
    "\n",
    "  [r'I want (.*)',\n",
    "  [  \"What would it mean to you if you got %1?\",\n",
    "    \"Why do you want %1?\",\n",
    "    \"What would you do if you got %1?\",\n",
    "    \"If you got %1, then what would you do?\"]],\n",
    "\n",
    "  [r'(.*) mother(.*)',\n",
    "  [  \"Tell me more about your mother.\",\n",
    "    \"What was your relationship with your mother like?\",\n",
    "    \"How do you feel about your mother?\",\n",
    "    \"How does this relate to your feelings today?\",\n",
    "    \"Good family relations are important.\"]],\n",
    "\n",
    "  [r'(.*) father(.*)',\n",
    "  [  \"Tell me more about your father.\",\n",
    "    \"How did your father make you feel?\",\n",
    "    \"How do you feel about your father?\",\n",
    "    \"Does your relationship with your father relate to your feelings today?\",\n",
    "    \"Do you have trouble showing affection with your family?\"]],\n",
    "\n",
    "  [r'(.*) child(.*)',\n",
    "  [  \"Did you have close friends as a child?\",\n",
    "    \"What is your favorite childhood memory?\",\n",
    "    \"Do you remember any dreams or nightmares from childhood?\",\n",
    "    \"Did the other children sometimes tease you?\",\n",
    "    \"How do you think your childhood experiences relate to your feelings today?\"]],\n",
    "\n",
    "  [r'(.*)\\?',\n",
    "  [  \"Why do you ask that?\",\n",
    "    \"Please consider whether you can answer your own question.\",\n",
    "    \"Perhaps the answer lies within yourself?\",\n",
    "    \"Why don't you tell me?\"]],\n",
    "\n",
    "  [r'quit',\n",
    "  [  \"Thank you for talking with me.\",\n",
    "    \"Good-bye.\",\n",
    "    \"Thank you, that will be $150.  Have a good day!\"]],\n",
    "\n",
    "  [r'(.*)',\n",
    "  [  \"Please tell me more.\",\n",
    "    \"Let's change focus a bit... Tell me about your family.\",\n",
    "    \"Can you elaborate on that?\",\n",
    "    \"Why do you say that %1?\",\n",
    "    \"I see.\",\n",
    "    \"Very interesting.\",\n",
    "    \"%1.\",\n",
    "    \"I see.  And what does that tell you?\",\n",
    "    \"How does that make you feel?\",\n",
    "    \"How do you feel when you say that?\"]]\n",
    "  ]\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "#  command_interface\n",
    "#----------------------------------------------------------------------\n",
    "def command_interface():\n",
    "  print('Therapist\\n---------')\n",
    "  print('Talk to the program by typing in plain English, using normal upper-')\n",
    "  print('and lower-case letters and punctuation.  Enter \"quit\" when done.')\n",
    "  print('='*72)\n",
    "  print('Hello.  How are you feeling today?')\n",
    "\n",
    "  s = ''\n",
    "  therapist = eliza();\n",
    "  while s != 'quit':\n",
    "    try:\n",
    "      s = input('> ')\n",
    "    except EOFError:\n",
    "      s = 'quit'\n",
    "    print(s)\n",
    "    while s[-1] in '!.':\n",
    "      s = s[:-1]\n",
    "    print(therapist.respond(s))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  command_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grammar for Python\n",
    "\n",
    "# NOTE WELL: You should also follow all the steps listed at\n",
    "# https://devguide.python.org/grammar/\n",
    "\n",
    "# Start symbols for the grammar:\n",
    "#       single_input is a single interactive statement;\n",
    "#       file_input is a module or sequence of commands read from an input file;\n",
    "#       eval_input is the input for the eval() functions.\n",
    "# NB: compound_stmt in single_input is followed by extra NEWLINE!\n",
    "single_input: NEWLINE | simple_stmt | compound_stmt NEWLINE\n",
    "file_input: (NEWLINE | stmt)* ENDMARKER\n",
    "eval_input: testlist NEWLINE* ENDMARKER\n",
    "\n",
    "decorator: '@' dotted_name [ '(' [arglist] ')' ] NEWLINE\n",
    "decorators: decorator+\n",
    "decorated: decorators (classdef | funcdef | async_funcdef)\n",
    "\n",
    "async_funcdef: 'async' funcdef\n",
    "funcdef: 'def' NAME parameters ['->' test] ':' suite\n",
    "\n",
    "parameters: '(' [typedargslist] ')'\n",
    "typedargslist: (tfpdef ['=' test] (',' tfpdef ['=' test])* [',' [\n",
    "        '*' [tfpdef] (',' tfpdef ['=' test])* [',' ['**' tfpdef [',']]]\n",
    "      | '**' tfpdef [',']]]\n",
    "  | '*' [tfpdef] (',' tfpdef ['=' test])* [',' ['**' tfpdef [',']]]\n",
    "  | '**' tfpdef [','])\n",
    "tfpdef: NAME [':' test]\n",
    "varargslist: (vfpdef ['=' test] (',' vfpdef ['=' test])* [',' [\n",
    "        '*' [vfpdef] (',' vfpdef ['=' test])* [',' ['**' vfpdef [',']]]\n",
    "      | '**' vfpdef [',']]]\n",
    "  | '*' [vfpdef] (',' vfpdef ['=' test])* [',' ['**' vfpdef [',']]]\n",
    "  | '**' vfpdef [',']\n",
    ")\n",
    "vfpdef: NAME\n",
    "\n",
    "stmt: simple_stmt | compound_stmt\n",
    "simple_stmt: small_stmt (';' small_stmt)* [';'] NEWLINE\n",
    "small_stmt: (expr_stmt | del_stmt | pass_stmt | flow_stmt |\n",
    "             import_stmt | global_stmt | nonlocal_stmt | assert_stmt)\n",
    "expr_stmt: testlist_star_expr (annassign | augassign (yield_expr|testlist) |\n",
    "                     ('=' (yield_expr|testlist_star_expr))*)\n",
    "annassign: ':' test ['=' test]\n",
    "testlist_star_expr: (test|star_expr) (',' (test|star_expr))* [',']\n",
    "augassign: ('+=' | '-=' | '*=' | '@=' | '/=' | '%=' | '&=' | '|=' | '^=' |\n",
    "            '<<=' | '>>=' | '**=' | '//=')\n",
    "# For normal and annotated assignments, additional restrictions enforced by the interpreter\n",
    "del_stmt: 'del' exprlist\n",
    "pass_stmt: 'pass'\n",
    "flow_stmt: break_stmt | continue_stmt | return_stmt | raise_stmt | yield_stmt\n",
    "break_stmt: 'break'\n",
    "continue_stmt: 'continue'\n",
    "return_stmt: 'return' [testlist]\n",
    "yield_stmt: yield_expr\n",
    "raise_stmt: 'raise' [test ['from' test]]\n",
    "import_stmt: import_name | import_from\n",
    "import_name: 'import' dotted_as_names\n",
    "# note below: the ('.' | '...') is necessary because '...' is tokenized as ELLIPSIS\n",
    "import_from: ('from' (('.' | '...')* dotted_name | ('.' | '...')+)\n",
    "              'import' ('*' | '(' import_as_names ')' | import_as_names))\n",
    "import_as_name: NAME ['as' NAME]\n",
    "dotted_as_name: dotted_name ['as' NAME]\n",
    "import_as_names: import_as_name (',' import_as_name)* [',']\n",
    "dotted_as_names: dotted_as_name (',' dotted_as_name)*\n",
    "dotted_name: NAME ('.' NAME)*\n",
    "global_stmt: 'global' NAME (',' NAME)*\n",
    "nonlocal_stmt: 'nonlocal' NAME (',' NAME)*\n",
    "assert_stmt: 'assert' test [',' test]\n",
    "\n",
    "compound_stmt: if_stmt | while_stmt | for_stmt | try_stmt | with_stmt | funcdef | classdef | decorated | async_stmt\n",
    "async_stmt: 'async' (funcdef | with_stmt | for_stmt)\n",
    "if_stmt: 'if' test ':' suite ('elif' test ':' suite)* ['else' ':' suite]\n",
    "while_stmt: 'while' test ':' suite ['else' ':' suite]\n",
    "for_stmt: 'for' exprlist 'in' testlist ':' suite ['else' ':' suite]\n",
    "try_stmt: ('try' ':' suite\n",
    "           ((except_clause ':' suite)+\n",
    "            ['else' ':' suite]\n",
    "            ['finally' ':' suite] |\n",
    "           'finally' ':' suite))\n",
    "with_stmt: 'with' with_item (',' with_item)*  ':' suite\n",
    "with_item: test ['as' expr]\n",
    "# NB compile.c makes sure that the default except clause is last\n",
    "except_clause: 'except' [test ['as' NAME]]\n",
    "suite: simple_stmt | NEWLINE INDENT stmt+ DEDENT\n",
    "\n",
    "test: or_test ['if' or_test 'else' test] | lambdef\n",
    "test_nocond: or_test | lambdef_nocond\n",
    "lambdef: 'lambda' [varargslist] ':' test\n",
    "lambdef_nocond: 'lambda' [varargslist] ':' test_nocond\n",
    "or_test: and_test ('or' and_test)*\n",
    "and_test: not_test ('and' not_test)*\n",
    "not_test: 'not' not_test | comparison\n",
    "comparison: expr (comp_op expr)*\n",
    "# <> isn't actually a valid comparison operator in Python. It's here for the\n",
    "# sake of a __future__ import described in PEP 401 (which really works :-)\n",
    "comp_op: '<'|'>'|'=='|'>='|'<='|'<>'|'!='|'in'|'not' 'in'|'is'|'is' 'not'\n",
    "star_expr: '*' expr\n",
    "expr: xor_expr ('|' xor_expr)*\n",
    "xor_expr: and_expr ('^' and_expr)*\n",
    "and_expr: shift_expr ('&' shift_expr)*\n",
    "shift_expr: arith_expr (('<<'|'>>') arith_expr)*\n",
    "arith_expr: term (('+'|'-') term)*\n",
    "term: factor (('*'|'@'|'/'|'%'|'//') factor)*\n",
    "factor: ('+'|'-'|'~') factor | power\n",
    "power: atom_expr ['**' factor]\n",
    "atom_expr: ['await'] atom trailer*\n",
    "atom: ('(' [yield_expr|testlist_comp] ')' |\n",
    "       '[' [testlist_comp] ']' |\n",
    "       '{' [dictorsetmaker] '}' |\n",
    "       NAME | NUMBER | STRING+ | '...' | 'None' | 'True' | 'False')\n",
    "testlist_comp: (test|star_expr) ( comp_for | (',' (test|star_expr))* [','] )\n",
    "trailer: '(' [arglist] ')' | '[' subscriptlist ']' | '.' NAME\n",
    "subscriptlist: subscript (',' subscript)* [',']\n",
    "subscript: test | [test] ':' [test] [sliceop]\n",
    "sliceop: ':' [test]\n",
    "exprlist: (expr|star_expr) (',' (expr|star_expr))* [',']\n",
    "testlist: test (',' test)* [',']\n",
    "dictorsetmaker: ( ((test ':' test | '**' expr)\n",
    "                   (comp_for | (',' (test ':' test | '**' expr))* [','])) |\n",
    "                  ((test | star_expr)\n",
    "                   (comp_for | (',' (test | star_expr))* [','])) )\n",
    "\n",
    "classdef: 'class' NAME ['(' [arglist] ')'] ':' suite\n",
    "\n",
    "arglist: argument (',' argument)*  [',']\n",
    "\n",
    "# The reason that keywords are test nodes instead of NAME is that using NAME\n",
    "# results in an ambiguity. ast.c makes sure it's a NAME.\n",
    "# \"test '=' test\" is really \"keyword '=' test\", but we have no such token.\n",
    "# These need to be in a single rule to avoid grammar that is ambiguous\n",
    "# to our LL(1) parser. Even though 'test' includes '*expr' in star_expr,\n",
    "# we explicitly match '*' here, too, to give it proper precedence.\n",
    "# Illegal combinations and orderings are blocked in ast.c:\n",
    "# multiple (test comp_for) arguments are blocked; keyword unpackings\n",
    "# that precede iterable unpackings are blocked; etc.\n",
    "argument: ( test [comp_for] |\n",
    "            test '=' test |\n",
    "            '**' test |\n",
    "            '*' test )\n",
    "\n",
    "comp_iter: comp_for | comp_if\n",
    "sync_comp_for: 'for' exprlist 'in' or_test [comp_iter]\n",
    "comp_for: ['async'] sync_comp_for\n",
    "comp_if: 'if' test_nocond [comp_iter]\n",
    "\n",
    "# not used in grammar, but may appear in \"node\" passed from Parser to Compiler\n",
    "encoding_decl: NAME\n",
    "\n",
    "yield_expr: 'yield' [yield_arg]\n",
    "yield_arg: 'from' test | testlist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
